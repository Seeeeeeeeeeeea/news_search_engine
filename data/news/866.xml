<?xml version='1.0' encoding='utf-8'?>
<doc><id>866</id><url>http://www.chinanews.com/gn/2025/11-28/10522713.shtml</url><title>形成监管、平台、用户联动共治 多管齐下防范AI技术滥用</title><datetime>2025-11-28 09:33:00</datetime><body>	形成监管、平台、用户联动共治
	多管齐下，防范AI技术滥用(民生一线)
	人工智能(AI)、深度合成等新技术快速发展，对加快形成新质生产力、实现经济社会高质量发展起到关键作用，也为人们的生活带来便利。然而，部分不法分子利用AI技术传播虚假信息，破坏网络生态，造成不良影响。
	多管齐下防范对AI技术的滥用，促进人工智能健康发展，有利于维护社会共同利益。《人工智能生成合成内容标识办法》通过标识提醒用户辨别虚假信息，明确相关服务主体的标识责任义务，规范制作、传播各环节标识行为。
	持续打击灰色产业链
	一天，林某躺在床上刷着短视频，一个名为“AI理财小助手”的账号出现在屏幕上。林某在其主页里浏览了一番，发现账号粉丝数显示“8.7万”，但最新视频的点赞数还不到三位数。
	“公式化命名、同质化内容、异常互动数据，这些是AI起号的特征。”某短视频平台内容安全部门负责人刘珊介绍。AI起号成为一些自媒体的牟利手段，利用AI生成发布吸引眼球的内容，在短时间内吸引大量粉丝，之后通过带货或者直接转让账号变现。
	“利用AI选择涨粉领域，打造能够吸粉的人设，账号内容也可以通过AI生成。”售卖“AI起号课程”的“培训师”杨某说。一方面不受做自媒体需要的专业知识、制作能力限制；另一方面，可以帮助精准吸粉，并保持“人设一致”。此外，还能同时操作多个账号，形成矩阵，互相引流，合作推广。
	“情绪急救：人生低谷期如何防止情绪崩盘”“深度疗愈：看见潜意识中的自己”……杨某向记者展示了一个刚开号不久的“心理学博主”的账号页面。每个标题看上去专业感十足，又直击特定群体心理需求。“其实文案全靠AI生成。”杨某说。
	虚假的人设、不严谨的内容、夸张的画面，如此起号，对网络空间环境危害不小。
	如何打击利用AI起号的行为？
	“AI起号的主要危害在于伪造，治理关键也在于此。”北京邮电大学互联网治理与法律研究中心执行主任谢永江认为，除了强化执法打击外，平台也应提高对深度伪造内容的检测精度，明确对AI造假起号等违规行为的界定和处罚标准等。
	“起号—转型—转卖”的灰色产业链，是AI起号相较其他AI伪造现象的独有特点。
	“根据反电信网络诈骗法规定，任何单位和个人不得非法买卖、出租、出借互联网账号。”某电商平台安全运营负责人表示，各个电商平台均已禁止账号转卖。但有一些账号交易还是通过社交媒体发布，借助“隐晦暗语”等私下进行。
	“卖号不仅是AI起号的变现途径，通常还伴随诈骗等违法犯罪行为。”北京师范大学法学院教授梁迎修建议，监管部门督促平台履行治理责任，建立违规账号“黑名单”，对高频、反复触犯平台规则的账号主体加大处罚力度，禁止违规账号进行带货、卖课等商业活动，持续开展AI造假起号整治，切断不法分子获利渠道。
	有效拦截仿冒营销内容
	“今天有事请大家帮忙……先拿出300单老家的土鸡蛋给大家发福利！”不久前，在某短视频平台上，一名广受喜爱的运动员“推销老家农产品”，弹幕和评论里全是“支持”“为偶像冲销量”的文字。其实，这些带货视频全都是利用AI仿冒的，其中一个商品链接显示已售出4.7万件。
	据某短视频平台负责人介绍，冒充社会知名人士的情况主要有几种：利用AI技术生成社会知名人士图片，用作账号头像，仿冒假冒他人；利用AI技术生成社会知名人士视频且不做标注；仿冒假冒社会名人账号和生成内容后，博取关注，通过开设橱窗售货等方式不当获利。
	如何治理这一乱象？
	“AI仿冒名人，归根到底还是利用AI造假。民法典对肖像权和声音权利的规定以及其他相关法规，都已作出相关保护。《人工智能生成合成内容标识办法》对人工智能生成合成内容标识提出要求。”梁迎修认为，关键还是要严格执法，公正司法。
	“从平台角度来说，除了压实自身责任，还要与用户联动，强化共治。”腾讯相关负责人表示，用户发现未标注AI生成标识的短视频时，可提交相关材料进行投诉。经平台审核通过的补充说明将以浮动标注形式展现在原视频页面。
	抖音相关负责人表示，平台已为社会知名人士建立肖像保护库，同时努力对仿冒营销内容进行有效拦截。
	多方协作建立辟谣机制
	“突发爆炸！火光冲天！伤亡不明！”一则“视频新闻”在网上流传，画面中火光冲天，引发当地群众恐慌。后来公安机关调查发现，这是账号所属机构使用AI批量生成的虚假新闻。该机构一天最多能生成4000至7000篇假新闻，每天收入在1万元以上。
	为何AI制作的虚假新闻在网络上屡禁不止？
	某新闻聚合平台内容安全负责人认为，一些平台的反虚假信息机制效率有待提升，某些账户在平台发布AI生成图片视频后，“疑似AI技术生成”的提示语数小时后才出现，未能及时提醒风险。
	中南大学法学院副院长杨清望认为，平台应根据权威信息立即对相关谣言采取清理、标签标记等措施，并处置违规账号。
	近年来，相关法律法规不断健全完善，向AI使用者和平台管理者亮明了法律底线。北京师范大学新闻传播学院教授许小可建议，针对生成和传播虚假信息的高风险领域，可以通过司法解释等形式明确各方义务边界，进一步制定科学合理的AI侵权责任认定指导标准。
	在以技术对抗虚假新闻方面，各地监管部门也在不断探索。“我们与科研机构、企业密切合作，进一步提高对恶意‘深度伪造’信息的监测预警和快速识别能力。通过与相关部门合作建立网络谣言巡查监测、核查反馈、会商研判、线索移送、打击处置的闭环机制，对AI合成的虚假信息第一时间依法依规处理。”辽宁沈阳市公安网络安全保卫部门负责人说。
	若因虚假消息遭受损失，责任谁来承担？浙江师范大学特聘教授乔巴生认为，内容制作方若涉嫌欺诈，应承担侵权责任；若平台未尽审核义务，需依法承担连带赔偿责任。此外，用户也应提升对虚假信息的鉴别能力。
	某短视频平台负责人建议，首先，警惕内容特征，如AI生成文本常出现逻辑断层、情感表达单一或事实细节模糊；视频可能存在面部表情不自然、光影异常或声音失真。其次，核查信息来源，优先选择权威媒体或官方渠道。腾讯相关负责人建议，在一些AI生成内容明显缺乏可信度、具有信息误导等特征时，用户可通过评论区互动等形式相互提醒，并通过投诉等形式及时反馈到平台。
	监管、平台与用户联动共治，通过技术检测、投诉机制和法律追责，共同筑牢诚信防线。(人民日报记者金歆)【编辑:李岩】
</body></doc>